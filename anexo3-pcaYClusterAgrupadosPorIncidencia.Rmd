---
title: "Anexo 3. Prueba 2. Datos agrupados por incidencia"
author: "Arancha Carpintero Guardiola"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    toc: true
    toc_depth: '6'
    df_print: paged
  html_notebook:
    theme: flatly
    toc: true
    toc_float: true
    toc_depth: 6
---

```{r}
library(gridExtra)
library(factoextra)
library(ggplot2)
library(tibble)
library(cluster)
```

# Análisis de los datos

```{r}
summary(dfGroupedByIncident)
```
Al igual que pasaba con el ejemplo anterior, los datos están en escalas muy diferentes, cosa que habrá que tener en cuenta para el PCA y el análisis Cluster.


```{r}
varianza = apply(X = dfGroupedByIncident, MARGIN = 2, FUN = var)
varianza
```
Podemos observar que las varianzas en las tres últimas columnas (activaciones canceladas, noche y hospital) no son nada grandes, al contrario, los datos están bastante igualados.

```{r}
cor(dfGroupedByIncident)
```

```{r}
plot(dfGroupedByIncident)
```
Aquí podemos observar que no hay datos con mucha covarianza. El único dato que destaca así mucho sería el ratio de activaciones por la noche y las cancelaciones.

### Preguntas de interés

```{r}
# dfGroupedByIncident <- rownames_to_column(dfGroupedByIncident, var = "codigo")
```

#### ¿Qué código tiene más activaciones asignadas? ¿Y menos?
```{r}
select(dfGroupedByIncident[order(-dfGroupedByIncident$activaciones_totales), ], -c(activaciones_canceladas, tie_medio_intervencion, noche, hospital))
```
El código que más se repite a lo largo de los 7 años es "Patología cardiovascular· con un total de casi 165.000 intervenciones totales, seguido de cerca de las intervenciones casuales. En último lugar tenemos los códigos referentes a la atención psicológica a Cuerpos de Seguridad y Bomberos, ocurriendo tan solo 2 y 1 vez respectivamente. Además destaca que ninguna de estas últimas requirió hospitalización y ocurrieron de día.

#### ¿Qué código tiene mayor ratio de cancelaciones? ¿Y menos?
```{r}
select(dfGroupedByIncident[order(-dfGroupedByIncident$activaciones_canceladas), ], -c(activaciones_totales, tie_medio_intervencion, noche, hospital))
```
El código con mayor ratio de cancelación, casi un 50% sería el "Servicio de formación / divulgación externa", seguido de cerca de los accidentes de tren. En último lugar tenemos 6 código que no han tenido ninguna cancelación en los 7 años que expande este dataset y llama la atención que muchos de estos son sobre atención psicológica.

#### ¿Qué código tiene mayor ratio de hospitalizaciones? ¿Y menos?
```{r}
select(dfGroupedByIncident[order(-dfGroupedByIncident$hospital), ], -c(activaciones_totales, tie_medio_intervencion, noche, activaciones_canceladas))
```
"Orden médica" y "Orden médica urgente / agresivo" son los dos códigos con mayor ratio de hospitalización, casi llegando al 95% de las veces. Como contexto, he cogido las definiciones que vienen dadas por el proveedor de los datos: 
Orden médica: Traslado psiquiátrico forzoso ordenado por un medico
Orden médica urgente / agresivo: Orden medica de traslado psiquiátrico urgente por peligrosidad/agresividad extrema del paciente

Como información adicional, hay un total de 15 códigos que nunca han requerido hospitalización en estos 7 años. También es verdad, que no son códigos que generen muchas activaciones, ninguno de ellos pasa de las 100 en total.

#### ¿Qué código suele pasar más por la noche? ¿Y por el día? ¿Hay más sucesos por la noche o por el día?
```{r}
select(dfGroupedByIncident[order(-dfGroupedByIncident$noche), ], -c(activaciones_totales, tie_medio_intervencion, hospital, activaciones_canceladas))
```
```{r}
totalEvents <- sum(dfGroupedByIncident$activaciones_totales)
nightProportion <- sum(dfGroupedByIncident$activaciones_totales * dfGroupedByIncident$noche) / totalEvents
dayProportion <- 1 - nightProportion


# Create data for the pie chart
dayNightData <- data.frame(
  Category = c("Noche", "Día"),
  Proportion = c(nightProportion, dayProportion)
)

# Create the pie chart
pieChart <- ggplot(dayNightData, aes(x = "", y = Proportion, fill = Category)) +
  geom_bar(width = 1, stat = "identity") +
  coord_polar("y", start = 0) +
  geom_text(aes(label = paste0(round(Proportion * 100, 1), "%")), position = position_stack(vjust = 0.5)) +
  labs(title = "Proporción de eventos entre día y noche") +
  theme_void()  # Remove background elements

pieChart
```
Como se puede observar, la mayoría de las intervenciones ocurren de día, lo cual si se piensa tiene sentido ya que es cuando más gente hay despierta y más emergencias pueden ocurrir. El código que más ocurre por la noche, pero con tan solo un 27% de las veces sería el de divulgación y formación. Por el otro extremo, tenemos 13 códigos que no han surgido nunca entre las 9pm y 9 am.


#### ¿Qué código tiene mayor media de tiempo de intervención? ¿Y menos?
```{r}
select(dfGroupedByIncident[order(-dfGroupedByIncident$tie_medio_intervencion), ], -c(activaciones_totales, noche, hospital, activaciones_canceladas))
```

# Análisis de Componentes Principales (PCA)
Lo primero haremos será escalar los datos, dejando fuera las columnas de hospital, noche y activaciones canceladas, ya que esas no están en magnitudes desproporcionadas.

```{r}
dfGroupedByIncidentScaled <- data.frame(dfGroupedByIncident)

dfGroupedByIncidentScaled$tie_medio_intervencion <- scale(dfGroupedByIncidentScaled$tie_medio_intervencion)
dfGroupedByIncidentScaled$activaciones_totales <- scale(dfGroupedByIncidentScaled$activaciones_totales)
dfGroupedByIncidentScaled$noche <- scale(dfGroupedByIncidentScaled$noche)
```

Aplicamos el PCA

```{r}
pcaIncidents = prcomp(dfGroupedByIncidentScaled)
pcaIncidents$rotation
```

```{r}
summary(pcaIncidents)
```
Como vemos, los cuatro primeros componentes explican por sí mismos casi el 88% de la variabilidad.

```{r}
plot(pcaIncidents, type = "l", main="Varianza por número de componentes")
```


```{r}
biplot(x = pcaIncidents, scale = 0, cex = 0.9, col = c("black", "blue"))
```

# Análisis Cluster
En esta sección veremos el análisis estadístico GAP para determinar el número óptimo de clústers, el análisis clúster con el algoritmo K-Means y por último el análisis silhoutte.


```{r}
gapSatisticIncidentsScaled <- clusGap(dfGroupedByIncidentScaled, FUN = pam, K.max = 10, B = 50)

fviz_gap_stat(gapSatisticIncidentsScaled)
```

```{r}
dfGroupedByIncidentNormalized <- data.frame(dfGroupedByIncident) 


normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

dfGroupedByIncidentNormalized$tie_medio_intervencion <- normalize(dfGroupedByIncidentNormalized$tie_medio_intervencion)
dfGroupedByIncidentNormalized$activaciones_totales <- normalize(dfGroupedByIncidentNormalized$activaciones_totales)
dfGroupedByIncidentNormalized$noche <- normalize(dfGroupedByIncidentNormalized$noche)
```

```{r}
set.seed(123)

gapSatisticIncidentNormalized <- clusGap(dfGroupedByIncidentNormalized, FUN = pam, K.max = 10, B = 50)

fviz_gap_stat(gapSatisticIncidentNormalized)
```

```{r}
set.seed(123)

kmeansModel3KNI <- kmeans(dfGroupedByIncidentNormalized, centers = 3, nstart = 25)

resultCluster <- cbind(cluster = kmeansModel3KNI$cluster, dfGroupedByIncidentNormalized)
fviz_cluster(kmeansModel3KNI,
             data = resultCluster,
             show.clust.cent = TRUE,
             geom=c("point", "text"),
             # ellipse = TRUE,
             ellipse.type = "convex",
             repel = TRUE,
             ggtheme = theme_bw())
```


```{r}
diss_mat <- dist(dfGroupedByIncidentNormalized)
sil3KNI <- silhouette(kmeansModel3KNI$cluster, diss_mat)

summary(sil3KNI)
```

```{r}
fviz_silhouette(sil3KNI)
```

